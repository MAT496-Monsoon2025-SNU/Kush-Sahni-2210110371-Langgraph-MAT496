{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course will use [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) because it is both popular and performant. As noted, please ensure that you have an `OPENAI_API_KEY`.\n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a useful how-to for all the things that you can do with chat models, but we'll show a few highlights below. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-openai` package. With this, we can instantiate our `ChatOpenAI` model object. If you are signing up for the API for the first time, you should receive [free credits](https://community.openai.com/t/understanding-api-limits-and-free-tier/498517) that can be applied to any of the models. You can see pricing for various models [here](https://openai.com/api/pricing/). The notebooks will default to `gpt-4o` because it's a good balance of quality, price, and speed [see more here](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini), but you can also opt for the lower priced `gpt-3.5` series models. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Kush! The meaning of life is a question that has intrigued humans for centuries, and it often depends on individual beliefs, cultural perspectives, and philosophical viewpoints. Some people find meaning through religion or spirituality, others through relationships, personal achievements, or contributing to the well-being of others. Philosophers like Albert Camus have suggested that life is inherently meaningless, but we can create our own meaning through our actions and choices. Ultimately, the meaning of life is a deeply personal question, and the answer can vary greatly from person to person. What are your thoughts on it?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 24, 'total_tokens': 139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CRE5tPEzjSmfbBCZnSrQJSBv19RNK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a01c804-1e6e-4489-9bea-9181dc5e406d-0', usage_metadata={'input_tokens': 24, 'output_tokens': 115, 'total_tokens': 139, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello there, Kush this side, What is the meaning of Life?\", name=\"Kush\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Kush! Sherlock Holmes' partner is Dr. John H. Watson. He is a medical doctor by profession, specifically a physician and surgeon. Watson often assists Holmes in his detective work and is also the narrator of most of the Sherlock Holmes stories written by Sir Arthur Conan Doyle.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 27, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CRE7B7cvAtgpUF9UJvRR7vIFD8GH9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a6ca7af-2019-4a19-a0c4-4b5f79aa3fb1-0', usage_metadata={'input_tokens': 27, 'output_tokens': 56, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke(\"Hello there, Kush this side, Who is the partner of Sherlock Holmes and what is his profession specialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here is a simple implementation of Binary Search in Python:\\n\\n```python\\ndef binary_search(arr, target):\\n    low = 0\\n    high = len(arr) - 1\\n    \\n    while low <= high:\\n        mid = (low + high) // 2\\n        if arr[mid] == target:\\n            return mid\\n        elif arr[mid] < target:\\n            low = mid + 1\\n        else:\\n            high = mid - 1\\n    \\n    return -1\\n\\n# Example usage\\narr = [1, 2, 3, 4, 5, 6, 7, 8, 9]\\ntarget = 5\\nresult = binary_search(arr, target)\\n\\nif result != -1:\\n    print(f\"Element found at index {result}\")\\nelse:\\n    print(\"Element not found\")\\n```\\n\\nThis code defines a function `binary_search` that takes a sorted array `arr` and a target value `target` as input. It then performs a binary search on the array to find the index of the target value. If the target value is found, the function returns the index of the target value in the array. If the target value is not found, the function returns -1.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 23, 'total_tokens': 277, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CRE6BRVGx9cbkzyK0UaRz7t2VppF5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a114ef6d-d353-4e54-b992-21620175cd6c-0', usage_metadata={'input_tokens': 23, 'output_tokens': 254, 'total_tokens': 277, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt35_chat.invoke(\"Hello there, Kush this side, Can you please tell the code for Binary Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks. \n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"Who is House MD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'House (TV series) - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/House_(TV_series)',\n",
       "  'content': 'House (also known as House, M.D.) is an American medical drama television series created by David Shore that originally aired on Fox from November 16, 2004, to May 21, 2012, for eight seasons. It features the life of Dr. Gregory House (Hugh Laurie), an unconventional, misanthropic, cynical medical genius who, despite his dependence on pain medication, successfully leads a team of diagnosticians at the fictional Princeton–Plainsboro Teaching Hospital (PPTH) in New Jersey. House often clashes [...] | Also known as | House, M.D. |\\n| Genre |  Medical drama  Black comedy |\\n| Created by | David Shore |\\n| Showrunner | David Shore |\\n| Starring |  Hugh Laurie  Lisa Edelstein  Omar Epps  Robert Sean Leonard  Jennifer Morrison  Jesse Spencer  Peter Jacobson  Kal Penn  Olivia Wilde  Amber Tamblyn  Odette Annable  Charlyne Yi |\\n| Opening theme | \"Teardrop \"Teardrop (song)\")\"by Massive Attack |\\n| Composers |  Jason Derlatka  Jon Ehrlich |\\n| Country of origin | United States | [...] Gregory House, M.D., often construed as a misanthropic medical genius, heads a team of diagnosticians at the Princeton–Plainsboro Teaching Hospital in New Jersey. The series is structured around a central plot with some supporting secondary stories and narratives that cross over seasons. Most episodes revolve around the diagnosis of a primary patient and start with a cold open set outside the hospital, showing events ending with the onset of the patient\\'s symptoms. The typical episode follows',\n",
       "  'score': 0.8800674},\n",
       " {'title': 'House (TV Series 2004–2012) - IMDb',\n",
       "  'url': 'https://www.imdb.com/title/tt0412142/',\n",
       "  'content': 'Reviewers say \\'House M.D.\\' is acclaimed for its compelling character dynamics, especially Hugh Laurie\\'s portrayal of Dr. Gregory House. The show is celebrated for its intricate medical cases, dark humor, and the blend of drama and comedy. However, some critics note repetitive plot structures and a shift towards personal relationships over medical intrigue in later seasons. Despite these issues, \\'House M.D.\\' is generally considered a standout in the medical drama genre, providing intellectual [...] House is a brilliant show medically speaking but so much more than that at the same time. The show is a kind of \"24\" meets medicine extravaganza. The main character, Dr. Gregory House, is played beautifully by Hugh Laurie. Dr. House is a bitter but brilliant doctor who is crippled in one leg due to the inability of doctors to properly diagnose his problem in time. This makes him a decidedly bitter person when dealing with others yet he is one of the best doctors in his field of diagnostic [...] \"House\" is one of the best new shows of the season that no one is watching.Yes, it is another medical drama (and haven\\'t we seen enough of those?) but what this show lacks in originality it makes up in character. Namely - Dr. Greg House.House is a cranky, cynical highly intelligent doctor with a limp that specializes in weird medical cases. Each week he, and his team of fresh faced young doctors, tackle some new medical mystery. With the use of CSI camera views and mouth-numbing medical jargon,',\n",
       "  'score': 0.77137923},\n",
       " {'title': 'Gregory House from House M.D. | CharacTour',\n",
       "  'url': 'https://www.charactour.com/hub/characters/view/Gregory-House.House-MD',\n",
       "  'content': 'Dr. Gregory House is the Head of Diagnostic Medicine at Princeton-Plainsboro Teaching Hospital where leads a team of handpicked young doctors. Brilliant, pessimistic, self-indulgent, sardonic, proud, and irritable, House hides most of his emotions behind his ever-present snide and witty comebacks. But his unconventional approach to his work makes him a frustrating superior to deal with.\\n\\n  + tv\\n  + 2004\\n  + 1446 Fans\\n\\n## Related Characters\\n\\nsign in [...] Profession... Head of Diagnostic Medicine at the Princeton-Plainsboro Teaching Hospital. House leads a team of handpicked young doctors at the hospital. But his dry, sarcastic humor and cynical approach to his work makes him a frustrating superior to deal with.',\n",
       "  'score': 0.7482976}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
